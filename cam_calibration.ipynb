{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera Calibration Using OpenCV\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time, random\n",
    "from image_pro import *\n",
    "\n",
    "def undistort_image(image, camera_matrix, distortion_coeffs, fill_color=(255, 255, 255)):\n",
    "    h, w = image.shape[:2]\n",
    "    # Compute the new optimal camera matrix\n",
    "    new_camera_matrix, valid_pix_roi = cv2.getOptimalNewCameraMatrix(camera_matrix, distortion_coeffs, (w, h), 1, (w, h))\n",
    "\n",
    "    # Undistort the image\n",
    "    undistorted_image = cv2.undistort(image, camera_matrix, distortion_coeffs, None, new_camera_matrix)\n",
    "\n",
    "    # Create a mask of the valid region\n",
    "    x, y, w, h = valid_pix_roi\n",
    "    mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
    "    mask[y:y+h, x:x+w] = 255\n",
    "\n",
    "    # Invert the mask to get the non-valid regions\n",
    "    inv_mask = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Fill the non-valid regions with the fill color\n",
    "    filled_image = undistorted_image.copy()\n",
    "    filled_image[inv_mask == 255] = fill_color\n",
    "\n",
    "    return filled_image\n",
    "\n",
    "square_size = 29  # in millimeters\n",
    "board_width = 7\n",
    "board_height = 5\n",
    "board_size = (board_width, board_height)\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "# 4x3 grid of points\n",
    "objp = np.zeros((board_width * board_height, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:board_width, 0:board_height].T.reshape(-1, 2)\n",
    "\n",
    "objpoints = []  # 3d point in real world space\n",
    "imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "images = glob.glob('*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, board_size, None)\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "        imgpoints.append(corners2)\n",
    "        \n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize camera\n",
    "camera = cv2.VideoCapture(2)  # Replace '0' with your camera source\n",
    "\n",
    "frame_processing_interval = 0  # Process a frame every 4 seconds\n",
    "last_processed_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "    frame = undistort_image(frame, mtx, dist)\n",
    "    # print(f\"width = {frame.shape[1]}, height = {frame.shape[0]}\")\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    current_time = time.time()\n",
    "    if current_time - last_processed_time >= frame_processing_interval:\n",
    "        last_processed_time = current_time\n",
    "\n",
    "        # Process the frame\n",
    "        image_processor = ImageProcessor(frame)\n",
    "        object_centers = image_processor.detect_objects()\n",
    "\n",
    "        # Visualize the processed frame\n",
    "        processed_frame = image_processor.draw_rectangles()\n",
    "        cv2.imshow(\"Processed Frame\", processed_frame)\n",
    "\n",
    "        # Select three random objects\n",
    "        if len(object_centers) > 3:\n",
    "            selected_objects = random.sample(object_centers, 3)\n",
    "        else:\n",
    "            selected_objects = object_centers\n",
    "\n",
    "        # Proceed with the selected objects for path planning\n",
    "        # ... (rest of the path planning logic)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2Dworld3D(im_P):\n",
    "    robot_coords = np.array([[-157.84, -132], [-457.84, -132], [-157.84, 95], [-457.84, 95]])  \n",
    "    image_coords = np.array([[0, 0], [640, 0], [0, 480], [640, 480]])  \n",
    "\n",
    "    H, _ = cv2.findHomography(image_coords, robot_coords)\n",
    "    \n",
    "    point_img = np.array(im_P, dtype=np.float32)\n",
    "    point_img = np.append(point_img, 1)\n",
    "    point_world = np.dot(H, point_img)  \n",
    "\n",
    "    point_world /= point_world[2]\n",
    "    point_world = point_world[:2]\n",
    "    \n",
    "    z_constant = -520\n",
    "    np.append(point_world, z_constant)\n",
    "    \n",
    "    return point_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta_robot import DeltaRobot\n",
    "r = 138.25\n",
    "h = 200\n",
    "s = 50\n",
    "k = 400\n",
    "Zt = 0\n",
    "robot = DeltaRobot(r, h, s, k, Zt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -27.29,  -47.27, -324.65])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot.calculate_fwd_kinematics(20, 20, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.84, 11.84, -0.0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot.calculate_inv_kinematics(-27.29, -47.27, -324.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def intersect_circles(x1, y1, r1, x2, y2, r2):\n",
    "    dist = math.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "\n",
    "    if dist > r1 + r2 or dist < abs(r1 - r2) or dist == 0:\n",
    "        return None  \n",
    "\n",
    "    a = (r1**2 - r2**2 + dist**2) / (2 * dist)\n",
    "    h = math.sqrt(r1**2 - a**2)\n",
    "\n",
    "    x3 = x1 + a * (x2 - x1) / dist\n",
    "    y3 = y1 + a * (y2 - y1) / dist\n",
    "\n",
    "    intersection1 = (x3 + h * (y2 - y1) / dist, y3 - h * (x2 - x1) / dist)\n",
    "    intersection2 = (x3 - h * (y2 - y1) / dist, y3 + h * (x2 - x1) / dist)\n",
    "\n",
    "    return intersection1 if intersection1[0] > intersection2[0] else intersection2\n",
    "\n",
    "# Example usage:\n",
    "print(intersect_circles(0, 0, 5, 10, 0, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./tomato_images/T7.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m image_processor \u001b[38;5;241m=\u001b[39m ImageProcessor(image)\n\u001b[0;32m      3\u001b[0m image_processor\u001b[38;5;241m.\u001b[39mdetect_objects()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"./tomato_images/T7.jpg\")\n",
    "image_processor = ImageProcessor(image)\n",
    "image_processor.detect_objects()\n",
    "processed_image = image_processor.draw_rectangles()\n",
    "desired_width = 300  # or any width that fits your screen\n",
    "desired_height = 400 # or any height that fits your screen\n",
    "resized_image = cv2.resize(processed_image, (desired_width, desired_height))\n",
    "\n",
    "# Display the resized image\n",
    "cv2.imshow(\"Processed Image\", resized_image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 3000, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([[852, 955, 1899, 2069], [1757, 1459, 2768, 2468]], ['orange', 'orange'], [0.9216803908348083, 0.673895001411438])\n"
     ]
    }
   ],
   "source": [
    "from image_pro import *\n",
    "import cv2\n",
    "import cvlib as cvl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = cv2.imread(\"./tomato_images/T7.jpg\")\n",
    "# image_processor = ImageProcessor(image)\n",
    "# image_processor.detect_objects()\n",
    "# processed_image = image_processor.draw_rectangles()\n",
    "processed_image = cvl.detect_common_objects(image)\n",
    "# desired_width = 300  # or any width that fits your screen\n",
    "# desired_height = 400 # or any height that fits your screen\n",
    "# resized_image = cv2.resize(processed_image, (desired_width, desired_height))\n",
    "\n",
    "print(processed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLOv8 inference on the frame\n",
    "        results = model(frame)\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylabel import importer\n",
    "\n",
    "category_mapping = {\n",
    "    'b_fully_ripened': 'fully_ripened',\n",
    "    'l_fully_ripened': 'fully_ripened',\n",
    "    'b_half_ripened': 'half_ripened',\n",
    "    'l_half_ripened': 'half_ripened',\n",
    "    'b_green': 'green',\n",
    "    'l_green': 'green',\n",
    "}\n",
    "\n",
    "path_to_coco_json = \"d:/DELL XPS Backup Bishal/Bishal/DELTA/Datasets/laboro/annotations/test.json\"\n",
    "dataset = importer.ImportCoco(path_to_coco_json, name=\"test_annots\")\n",
    "\n",
    "for annotation in dataset.df.iterrows():\n",
    "    annotation = annotation[1]  \n",
    "    new_cat = category_mapping.get(annotation[\"cat_name\"])\n",
    "    if new_cat:\n",
    "        dataset.df.at[annotation.name, \"cat_name\"] = new_cat\n",
    "\n",
    "dataset.df['cat_name'] = dataset.df['cat_name'].astype('category')\n",
    "dataset.df['cat_id'] = dataset.df['cat_name'].cat.codes\n",
    "\n",
    "\n",
    "dataset.export.ExportToYoloV5(output_path=\"d:/DELL XPS Backup Bishal/Bishal/DELTA/Datasets/laboro/val/labels/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def move_xml_files(source_dir, target_dir):\n",
    "\n",
    "    # Ensure target directory exists, if not, create it\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "\n",
    "    # Count of files moved\n",
    "    files_moved = 0\n",
    "\n",
    "    # Iterate over all files in the source directory\n",
    "    for filename in os.listdir(source_dir):\n",
    "        if filename.endswith('.xml'):\n",
    "            # Construct full file path\n",
    "            source_file = os.path.join(source_dir, filename)\n",
    "            target_file = os.path.join(target_dir, filename)\n",
    "\n",
    "            # Move the file\n",
    "            shutil.move(source_file, target_file)\n",
    "            files_moved += 1\n",
    "            print(f\"Moved: {source_file} to {target_file}\")\n",
    "\n",
    "    print(f\"Total of {files_moved} .xml files moved from {source_dir} to {target_dir}\")\n",
    "\n",
    "# Usage example:\n",
    "images_dir = \"d:/DELL XPS Backup Bishal/Bishal/DELTA/Datasets/Drive/Tomato Images/Images\"\n",
    "annots_dir = \"d:/DELL XPS Backup Bishal/Bishal/DELTA/Datasets/Drive/Tomato Images/Annotations\"\n",
    "move_xml_files(images_dir, annots_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylabel import importer\n",
    "\n",
    "label_path = \"d:/DELL XPS Backup Bishal/Bishal/DELTA/Datasets/Drive/Tomato Images/Annotations\"\n",
    "path_to_yolo = \"d:/DELL XPS Backup Bishal/Bishal/DELTA/Datasets/Drive/Tomato Images/Labels\"\n",
    "dataset_name = \"drive images\"\n",
    "\n",
    "dataset = importer.ImportVOC(label_path, dataset_name)\n",
    "dataset.export.ExportToYoloV5(path_to_yolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def list_files_in_directory(directory):\n",
    "    logging.info(f\"Listing files in {directory}:\")\n",
    "    if os.path.exists(directory):\n",
    "        files = os.listdir(directory)\n",
    "        for file in files:\n",
    "            logging.info(file)\n",
    "    else:\n",
    "        logging.error(f\"Directory does not exist: {directory}\")\n",
    "\n",
    "def move_files(files, source, destination):\n",
    "    for file in files:\n",
    "        source_file = os.path.join(source, file)\n",
    "        destination_file = os.path.join(destination, file)\n",
    "\n",
    "        if os.path.exists(source_file) and os.path.getsize(source_file) > 0:\n",
    "            shutil.move(source_file, destination_file)\n",
    "            logging.info(f\"Moved: {source_file} to {destination_file}\")\n",
    "        else:\n",
    "            logging.warning(f\"File not found or is empty: {source_file}\")\n",
    "\n",
    "def split_data_set(image_dir, label_dir, train_size=0.8):\n",
    "    list_files_in_directory(image_dir)  # List files for diagnostics\n",
    "\n",
    "    images = [file for file in os.listdir(image_dir) if file.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    if not images:\n",
    "        logging.error(\"No image files found. Check the directory and file extensions.\")\n",
    "        return\n",
    "\n",
    "    random.shuffle(images)\n",
    "    split_point = int(len(images) * train_size)\n",
    "\n",
    "    train_images = images[:split_point]\n",
    "    val_images = images[split_point:]\n",
    "\n",
    "    for folder in ['train', 'val']:\n",
    "        for subdir in [image_dir, label_dir]:\n",
    "            os.makedirs(os.path.join(subdir, folder), exist_ok=True)\n",
    "\n",
    "    move_files(train_images, image_dir, os.path.join(image_dir, 'train'))\n",
    "    move_files(val_images, image_dir, os.path.join(image_dir, 'val'))\n",
    "    move_files([f.replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt') for f in train_images], label_dir, os.path.join(label_dir, 'train'))\n",
    "    move_files([f.replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt') for f in val_images], label_dir, os.path.join(label_dir, 'val'))\n",
    "\n",
    "    logging.info(f\"Dataset split into {len(train_images)} training and {len(val_images)} validation samples.\")\n",
    "\n",
    "# Usage\n",
    "path_to_yolo = \"d:/DELL XPS Backup Bishal/Bishal/DELTA/Datasets/Drive/Tomato Images/Labels\"\n",
    "path_to_images = \"d:/DELL XPS Backup Bishal/Bishal/DELTA/Datasets/Drive/Tomato Images/Images\"\n",
    "\n",
    "split_data_set(path_to_images, path_to_yolo, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.random.randn(3, 3)\n",
    "b = np.random.randn(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27239664,  0.04891296,  0.25507883],\n",
       "       [ 1.01454214, -0.33875551, -0.05687084],\n",
       "       [-0.97649445,  3.10000794, -0.27028196]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.06182036],\n",
       "       [-0.0777233 ],\n",
       "       [ 0.84677257]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2892363 ,  0.05193677,  0.2708479 ],\n",
       "       [-0.07885356,  0.0263292 ,  0.00442019],\n",
       "       [-0.82686871,  2.62500169, -0.22886735]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
