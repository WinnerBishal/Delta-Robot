{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load calibration parameters from JSON file\n",
    "with open('cameraParams.json', 'r') as file:\n",
    "    params = json.load(file)\n",
    "\n",
    "# Convert the loaded data to numpy arrays\n",
    "camera_matrix = np.array(params['IntrinsicMatrix'])\n",
    "radial_distortion = np.array(params['RadialDistortion'])\n",
    "tangential_distortion = np.array(params['TangentialDistortion'])\n",
    "\n",
    "# OpenCV expects at least 5 distortion coefficients: k1, k2, p1, p2, k3\n",
    "# If you only have k1 and k2 (as it seems in this case), you can append zeros for p1, p2, and k3\n",
    "dist_coeffs = np.hstack((radial_distortion, tangential_distortion, [0]))\n",
    "\n",
    "# Assuming a fixed depth Z\n",
    "Z = 1000  # Replace with the actual known depth value\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Optical center (principal point) from the camera matrix\n",
    "    cx = int(camera_matrix[0, 2])\n",
    "    cy = int(camera_matrix[1, 2])\n",
    "    \n",
    "    # Choose an offset from the optical center (for example, 100 pixels right and 50 pixels down)\n",
    "    offset_x = -100\n",
    "    offset_y = 50\n",
    "    pixel_coords_offset = np.array([[[cx + offset_x, cy + offset_y]]], dtype='float32')\n",
    "    \n",
    "    # Convert the pixel coordinates to real-world coordinates\n",
    "    undistorted_pixel_coords = cv2.undistortPoints(pixel_coords_offset, camera_matrix, dist_coeffs, P=camera_matrix)\n",
    "    X = (undistorted_pixel_coords[0][0][0] * Z) / camera_matrix[0, 0]\n",
    "    Y = (undistorted_pixel_coords[0][0][1] * Z) / camera_matrix[1, 1]\n",
    "    \n",
    "    # Overlay the optical center on the live feed\n",
    "    cv2.circle(frame, (cx, cy), 5, (0, 255, 0), -1)\n",
    "    cv2.putText(frame, \"Optical Center\", (cx - 50, cy - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Overlay the offset point and its real-world coordinates\n",
    "    cv2.circle(frame, (cx + offset_x, cy + offset_y), 5, (0, 0, 255), -1)\n",
    "    coord_text = f\"World Coords: X={X:.2f}, Y={Y:.2f}, Z={Z:.2f}\"\n",
    "    cv2.putText(frame, coord_text, (cx + offset_x + 10, cy + offset_y + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "    \n",
    "    # Show the frame\n",
    "    cv2.imshow('Live Stream with Coordinates', frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.1040e+01, -2.1000e-01, -3.2038e+02,  1.0000e+00])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import roboticstoolbox as rtb\n",
    "import numpy as np\n",
    "\n",
    "# Create a rotation matrix (-90 degrees around the Z axis)\n",
    "Rz = rtb.ET.Rz(-np.pi/2).A()\n",
    "Ry = rtb.ET.Ry(-np.pi/2).A()\n",
    "dT = np.array([-222.42, 367.68, 484.05])\n",
    "\n",
    "R_c = np.matmul(Rz, Ry)\n",
    "R_c[:3, 3] = dT\n",
    "\n",
    "P0 = np.ones((4, ))\n",
    "P1 = np.array([-222.63, 47.3, 433.01])\n",
    "P0[:3] = P1\n",
    "\n",
    "R_c_inv = np.linalg.inv(R_c)\n",
    "P2 = np.matmul(R_c_inv, P0)\n",
    "P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 100., -100., -400.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_z = rtb.ET.Rz(-90, 'degrees').A()[:3, :3]\n",
    "P0 = [100, 100, -400]\n",
    "np.matmul(R_z, P0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -50.62,   -0.  , -296.89])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from delta_robot import *\n",
    "r = 139.6\n",
    "h = 200\n",
    "s = 49.84\n",
    "k = 400\n",
    "Zt = 0\n",
    "robot = DeltaRobot(r, h, s, k, Zt)\n",
    "\n",
    "robot.calculate_fwd_kinematics(20, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-9.43, -15.39, -21.41]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot.calculate_inv_kinematics(49.28, 29.98, -379.06)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
